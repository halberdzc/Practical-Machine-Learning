<html>

<head>
Practical Machine Learning
Course Project by Yuri Plotkin. Sunday, July 26th, 2015.
</head>

<body>

Project Scope:

The goal of your project is to predict the manner in which they did the exercise. This is the "classe" variable in the training set. You may use any of the other variables to predict with. You should create a report describing how you built your model, how you used cross validation, what you think the expected out of sample error is, and why you made the choices you did. You will also use your prediction model to predict 20 different test cases.

<br>
<br>

Dataset Background:

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways:

  Class A: Exactly according to the specification (correct method)
  Class B: Throwing the elbows to the front
  Class C: Lifting the dumbbell only halfway
  Class D: Lowering the dumbbell only halfway
  Class E: Throwing the hips to the front
  
<br><br>
<b>Reproducibility</b>
Loading libraries and setting the seed of the algorithm function ensures consistent results.
<br>

<!--begin.rcode
library(caret)
library(randomForest)
library(rpart)
library(rpart.plot)
library(rattle)
set.seed(111)
end.rcode-->

<br>
<b>Loading and Cleaning the Data</b>
<br>
Missing values and unecessary classification variables are deleted.
<br>

<!--begin.rcode

    train_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
    test_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
    
    #Storing data files in memory
    train_data <- read.csv(url(train_url), na.strings=c("NA","#DIV/0!",""))
    test_data <- read.csv(url(test_url), na.strings=c("NA","#DIV/0!",""))
    
    #Dimension Check (to know the number of variables in the data frame)
    dim_train <- dim(train_data)
    dim_test <- dim(test_data)
    
    #Remove columns that are incomplete(have missing values)
    train_data_new <- train_data[,colSums(is.na(train_data)) == 0]
    test_data_new <- test_data[,colSums(is.na(test_data)) == 0]
    
    #Minimize the size of the data frame by getting rid of variables you do not need 
    #(user_name, raw_timestamp_part_1, raw_timestamp_part_, 2 cvtd_timestamp, new_window, 
    #and num_window; columns 1 to 7)
    train_data_new <- train_data_new[,-c(1:7)]
    test_data_new <- test_data_new[,-c(1:7)]
    
    #Re-check the dimensions of the new training and test data sets
    dim_train_new <- dim(train_data_new)
    dim_test_new <- dim(test_data_new)
    
end.rcode-->

<br>
<b>Partitioning the Data Set</b><br>
To perform cross-validation on the training set, the 19,622 observations will be partitioned into two data sets using a standard 60/40 (the former larger section will go into training, and the latter into testing). This testing set is independent from the initial testing set removed for use in final validation. 
<br>

<!--begin.rcode

    data_train <- createDataPartition(y=train_data_new$classe, p=0.60, list=FALSE)
    Training <- train_data_new[data_train, ]
    Testing <- train_data_new[-data_train, ]
    dim(Training)
    dim(Testing)
    
end.rcode-->

<br>The distribution of the "Classe"" variable within the Training Data was also plotted (Figure 1). <br>

<!--begin.rcode
    win.graph()
    plot(Training$classe, col="lightblue", main="Distribution of the Classification Variable 'classe' within the Training Data Set", xlab="Classe")
    
end.rcode-->

<br>
<b>Decision Tree Prediction Model</b>
<br>

<!--begin.rcode

  #Decision Tree Model
  dec_tree <- rpart(classe ~ ., data=Training, method="class")
  
  #Predicting
  dec_tree_predict <- predict(dec_tree, Testing, type = "class")
  
  #Testing results on the myTesting data set
  confusionMatrix(dec_tree_predict, Testing$classe)

end.rcode-->

<br>Plot Decision Tree Prediction<br> 

<!--begin.rcode

  win.graph()
  fancyRpartPlot(dec_tree, cex=.5,under.cex=1,shadow.offset=0)

end.rcode-->

<br>
<b>Random Forest Prediction Model</b>
<br>

<!--begin.rcode
    #Decision Tree Model
    random_forest <- rpart(classe ~ ., data=Training, method="class")
            
    #Predicting
    rand_forr_predict <- predict(random_forest, Testing, type = "class")
    
    #Testing results on the myTesting data set
    confusionMatrix(rand_forr_predict, Testing$classe)
    
end.rcode-->

<br>
<b>Model Comparison</b>The Random Forest model was chosen as the final model for its higher accuracy (percentage of correctly classified observations). The expected out-of-sample error can be calculated as 1-(accuracy of predictions) within a cross-validation sample with thousands of entries. Since our test data contains very few entries (20), we expect none of the samples to be misclassified. 
<br><br>
<b>Creating a text file with the Random Forest Prediction</b>
<br>

<!--begin.rcode
     # Applying Random Forest algorithm to the original Testing data set
    final_model <- predict(random_forest,  test_data, type = "class")
    final_model
    
    
    # Generating files with predictions to submit for assignment
    pml_write_files = function(x){
      n = length(x)
      for(i in 1:n){
        filename = paste0("problem_id_",i,".txt")
        write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
      }
    }
    
    pml_write_files(final_model)
end.rcode-->
